{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "from loaders.dataloader import DataLoader\n",
    "from opt import parse_opt\n",
    "from pprint import pprint\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "from layers.match import AdaptiveReconstruct\n",
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'att_res_weight': 1.0,\n",
      " 'att_weight': 1.0,\n",
      " 'batch_size': 5,\n",
      " 'bidirectional': 1,\n",
      " 'checkpoint_path': 'output',\n",
      " 'dataset': 'refcoco',\n",
      " 'decode_bidirectional': 0,\n",
      " 'exp_id': '',\n",
      " 'gpuid': 0,\n",
      " 'grad_clip': 0.1,\n",
      " 'id': 'mrcn_cmr_with_st',\n",
      " 'imdb_name': 'coco_minus_refer',\n",
      " 'iters': 1250000,\n",
      " 'jemb_dim': 512,\n",
      " 'jemb_drop_out': 0.1,\n",
      " 'lang_rank_weight': 1.0,\n",
      " 'lang_res_weight': 1.0,\n",
      " 'language_eval': 0,\n",
      " 'learning_rate': 0.0004,\n",
      " 'learning_rate_decay_every': 8000,\n",
      " 'learning_rate_decay_start': 8000,\n",
      " 'load_best_score': 1,\n",
      " 'loss_combined': 5.0,\n",
      " 'loss_divided': 1.0,\n",
      " 'losses_log_every': 25,\n",
      " 'margin': 0.1,\n",
      " 'max_iters': 30000,\n",
      " 'net_name': 'res101',\n",
      " 'num_cxt': 5,\n",
      " 'num_sents': -1,\n",
      " 'optim_alpha': 0.8,\n",
      " 'optim_beta': 0.999,\n",
      " 'optim_epsilon': 1e-08,\n",
      " 'rnn_drop_out': 0.2,\n",
      " 'rnn_hidden_size': 512,\n",
      " 'rnn_num_layers': 1,\n",
      " 'rnn_type': 'lstm',\n",
      " 'sample_ratio': 0.3,\n",
      " 'save_checkpoint_every': 2000,\n",
      " 'seed': 24,\n",
      " 'seq_per_ref': 3,\n",
      " 'splitBy': 'unc',\n",
      " 'start_from': None,\n",
      " 'tag': 'notime',\n",
      " 'use_IoU': 1,\n",
      " 'variable_lengths': 1,\n",
      " 'vis_feats_type': 'res101',\n",
      " 'vis_res_weight': 0.01,\n",
      " 'visual_cxt_type': 'frcn',\n",
      " 'visual_drop_out': 0.2,\n",
      " 'visual_fuse_mode': 'concat',\n",
      " 'visual_init_norm': 20,\n",
      " 'visual_rank_weight': 1.0,\n",
      " 'visual_sample_ratio': 0.3,\n",
      " 'visual_use_bn': -1,\n",
      " 'visual_use_cxt': 1,\n",
      " 'weight_decay': 0.0005,\n",
      " 'window_scale': 2.5,\n",
      " 'with_st': 1,\n",
      " 'word_drop_out': 0.5,\n",
      " 'word_embedding_size': 512,\n",
      " 'word_vec_size': 512}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# Data input settings\n",
    "parser.add_argument('--dataset', type=str, default='refcoco', help='name of dataset')\n",
    "parser.add_argument('--splitBy', type=str, default='unc', help='who splits this dataset')\n",
    "parser.add_argument('--start_from', type=str, default=None, help='continuing training from saved model')\n",
    "# FRCN setting\n",
    "parser.add_argument('--imdb_name', default='coco_minus_refer', help='image databased trained on.')\n",
    "parser.add_argument('--net_name', default='res101', help='net_name: res101 or vgg16')\n",
    "parser.add_argument('--iters', default=1250000, type=int, help='iterations we trained for faster R-CNN')\n",
    "parser.add_argument('--tag', default='notime', help='on default tf, don\\'t change this!')\n",
    "parser.add_argument('--vis_feats_type', type=str, default='res101', help='visual features type: vgg16 or res101')\n",
    "# Visual Encoder Setting\n",
    "parser.add_argument('--visual_sample_ratio', type=float, default=0.3, help='ratio of same-type objects over different-type objects')\n",
    "parser.add_argument('--visual_fuse_mode', type=str, default='concat', help='concat or mul')\n",
    "parser.add_argument('--visual_init_norm', type=float, default=20, help='norm of each visual representation')\n",
    "parser.add_argument('--visual_use_bn', type=int, default=-1, help='>0: use bn, -1: do not use bn in visual layer')    \n",
    "parser.add_argument('--visual_use_cxt', type=int, default=1, help='if we use contxt')\n",
    "parser.add_argument('--visual_cxt_type', type=str, default='frcn', help='frcn or res101')\n",
    "parser.add_argument('--visual_drop_out', type=float, default=0.2, help='dropout on visual encoder')\n",
    "parser.add_argument('--window_scale', type=float, default=2.5, help='visual context type')\n",
    "# Visual Feats Setting\n",
    "parser.add_argument('--with_st', type=int, default=1, help='if incorporating same-type objects as contexts')\n",
    "parser.add_argument('--num_cxt', type=int, default=5, help='how many surrounding objects do we use')\n",
    "# Language Encoder Setting\n",
    "parser.add_argument('--word_embedding_size', type=int, default=512, help='the encoding size of each token')\n",
    "parser.add_argument('--word_vec_size', type=int, default=512, help='further non-linear of word embedding')\n",
    "parser.add_argument('--word_drop_out', type=float, default=0.5, help='word drop out after embedding')\n",
    "parser.add_argument('--bidirectional', type=int, default=1, help='bi-rnn')\n",
    "parser.add_argument('--rnn_hidden_size', type=int, default=512, help='hidden size of LSTM')\n",
    "parser.add_argument('--rnn_type', type=str, default='lstm', help='rnn, gru or lstm')\n",
    "parser.add_argument('--rnn_drop_out', type=float, default=0.2, help='dropout between stacked rnn layers')\n",
    "parser.add_argument('--rnn_num_layers', type=int, default=1, help='number of layers in lang_encoder')\n",
    "parser.add_argument('--variable_lengths', type=int, default=1, help='use variable length to encode') \n",
    "# Joint Embedding setting\n",
    "parser.add_argument('--jemb_drop_out', type=float, default=0.1, help='dropout in the joint embedding')\n",
    "parser.add_argument('--jemb_dim', type=int, default=512, help='joint embedding layer dimension')\n",
    "# Reconstruct Settings\n",
    "parser.add_argument('--decode_bidirectional', type=int, default=0, help='whther to use bidirection LSTM in reconstrcution')\n",
    "# Loss Setting\n",
    "parser.add_argument('--att_weight', type=float, default=1.0, help='weight on attribute prediction')\n",
    "parser.add_argument('--visual_rank_weight', type=float, default=1.0, help='weight on paired (ref, sent) over unpaired (neg_ref, sent)')\n",
    "parser.add_argument('--lang_rank_weight', type=float, default=1.0, help='weight on paired (ref, sent) over unpaired (ref, neg_sent)')\n",
    "parser.add_argument('--margin', type=float, default=0.1, help='margin for ranking loss')\n",
    "parser.add_argument('--lang_res_weight', type=float, default=1.0, help='weight on language reconstruction loss')\n",
    "parser.add_argument('--vis_res_weight', type=float, default=0.01, help='weight on visual reconstruction loss')\n",
    "parser.add_argument('--att_res_weight', type=float, default=1.0, help='weight on attribute reconstruction loss')\n",
    "parser.add_argument('--loss_combined', type=float, default=5.0, help='weight on loss_combined')\n",
    "parser.add_argument('--loss_divided', type=float, default=1.0, help='weight on loss_divided' )\n",
    "# Optimization: General\n",
    "parser.add_argument('--max_iters', type=int, default=30000, help='max number of iterations to run')\n",
    "parser.add_argument('--sample_ratio', type=float, default=0.3, help='ratio of same-type objects over different-type objects')\n",
    "parser.add_argument('--batch_size', type=int, default=5, help='batch size in number of images per batch')\n",
    "parser.add_argument('--grad_clip', type=float, default=0.1, help='clip gradients at this value')\n",
    "parser.add_argument('--seq_per_ref', type=int, default=3, help='number of expressions per object during training')\n",
    "parser.add_argument('--learning_rate_decay_start', type=int, default=8000, help='at what iter to start decaying learning rate')\n",
    "parser.add_argument('--learning_rate_decay_every', type=int, default=8000, help='every how many iters thereafter to drop LR by half')\n",
    "parser.add_argument('--optim_epsilon', type=float, default=1e-8, help='epsilon that goes into denominator for smoothing')\n",
    "parser.add_argument('--learning_rate', type=float, default=4e-4, help='learning rate')\n",
    "parser.add_argument('--optim_alpha', type=float, default=0.8, help='alpha for adam')\n",
    "parser.add_argument('--optim_beta', type=float, default=0.999, help='beta used for adam')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0005, help='weight decay for adam')\n",
    "# Evaluation/Checkpointing\n",
    "parser.add_argument('--num_sents', type=int, default=-1, help='how many images to use when periodically evaluating the validation loss? (-1 = all)')\n",
    "parser.add_argument('--save_checkpoint_every', type=int, default=2000, help='how often to save a model checkpoint?')\n",
    "parser.add_argument('--checkpoint_path', type=str, default='output', help='directory to save models')   \n",
    "parser.add_argument('--language_eval', type=int, default=0, help='Evaluate language as well (1 = yes, 0 = no)?')\n",
    "parser.add_argument('--losses_log_every', type=int, default=25, help='How often do we snapshot losses, for inclusion in the progress dump? (0 = disable)')\n",
    "parser.add_argument('--load_best_score', type=int, default=1, help='Do we load previous best score when resuming training.')      \n",
    "parser.add_argument('--use_IoU', type=int, default=1, help='Whether to use IoU evaluation or not')\n",
    "# misc\n",
    "parser.add_argument('--id', type=str, default='mrcn_cmr_with_st', help='an id identifying this run/job.')\n",
    "parser.add_argument('--seed', type=int, default=24, help='random number generator seed to use')\n",
    "parser.add_argument('--gpuid', type=int, default=0, help='which gpu to use, -1 = use CPU')\n",
    "parser.add_argument('--exp_id', type=str, default='', help='experiment id')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "opt = vars(args)\n",
    "pprint(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader loading data.json:  ../cache/prepro/refcoco_unc/data.json\n",
      "vocab size is  1999\n",
      "object cateogry size is  80\n",
      "we have 19994 images.\n",
      "we have 196771 anns.\n",
      "we have 50000 refs.\n",
      "we have 142210 sentences.\n",
      "label_length is  10\n",
      "Loader loading data.h5:  ../cache/prepro/refcoco_unc/data.h5\n",
      "assigned 16994 images to split train\n",
      "assigned 750 images to split testB\n",
      "assigned 1500 images to split val\n",
      "assigned 750 images to split testA\n"
     ]
    }
   ],
   "source": [
    "opt['dataset_splitBy'] = opt['dataset'] + '_' + opt['splitBy']\n",
    "data_json = osp.join('../cache/prepro', opt['dataset_splitBy'], 'data.json')\n",
    "data_h5 = osp.join('../cache/prepro', opt['dataset_splitBy'], 'data.h5')\n",
    "loader = DataLoader(data_h5=data_h5, data_json=data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/Kranthi/Maitreya/Manish/ARN/tools/../pyutils/mask-faster-rcnn/lib/model/config.py:365: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      " 'ANCHOR_SCALES': [4, 8, 16, 32],\n",
      " 'DATA_DIR': '/datasets/Kranthi/Maitreya/Manish/ARN/pyutils/mask-faster-rcnn/data',\n",
      " 'DATA_DIR_IMAGE': '/datasets/Kranthi/Maitreya/Manish/ARN/data/images',\n",
      " 'EXP_DIR': 'res101',\n",
      " 'MASK_SIZE': 14,\n",
      " 'MATLAB': 'matlab',\n",
      " 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,\n",
      "               'FIXED_LAYERS': 5,\n",
      "               'REGU_DEPTH': False,\n",
      "               'WEIGHT_DECAY': 4e-05},\n",
      " 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),\n",
      " 'POOLING_ALIGN': False,\n",
      " 'POOLING_MODE': 'crop',\n",
      " 'POOLING_SIZE': 7,\n",
      " 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},\n",
      " 'RNG_SEED': 3,\n",
      " 'ROOT_DIR': '/datasets/Kranthi/Maitreya/Manish/ARN/pyutils/mask-faster-rcnn',\n",
      " 'TEST': {'BBOX_REG': True,\n",
      "          'HAS_RPN': True,\n",
      "          'MAX_SIZE': 1000,\n",
      "          'MODE': 'nms',\n",
      "          'NMS': 0.3,\n",
      "          'PROPOSAL_METHOD': 'gt',\n",
      "          'RPN_NMS_THRESH': 0.7,\n",
      "          'RPN_POST_NMS_TOP_N': 300,\n",
      "          'RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'RPN_TOP_N': 5000,\n",
      "          'SCALES': [600],\n",
      "          'SVM': False},\n",
      " 'TRAIN': {'ASPECT_GROUPING': False,\n",
      "           'BATCH_SIZE': 256,\n",
      "           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],\n",
      "           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],\n",
      "           'BBOX_NORMALIZE_TARGETS': True,\n",
      "           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,\n",
      "           'BBOX_REG': True,\n",
      "           'BBOX_THRESH': 0.5,\n",
      "           'BG_THRESH_HI': 0.5,\n",
      "           'BG_THRESH_LO': 0.0,\n",
      "           'BIAS_DECAY': False,\n",
      "           'DISPLAY': 20,\n",
      "           'DOUBLE_BIAS': False,\n",
      "           'FG_FRACTION': 0.25,\n",
      "           'FG_THRESH': 0.5,\n",
      "           'FROM_FRCN': False,\n",
      "           'GAMMA': 0.1,\n",
      "           'HAS_RPN': True,\n",
      "           'IMS_PER_BATCH': 1,\n",
      "           'LEARNING_RATE': 0.001,\n",
      "           'MAX_SIZE': 1000,\n",
      "           'MOMENTUM': 0.9,\n",
      "           'PROPOSAL_METHOD': 'gt',\n",
      "           'RPN_BATCHSIZE': 256,\n",
      "           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'RPN_CLOBBER_POSITIVES': False,\n",
      "           'RPN_FG_FRACTION': 0.5,\n",
      "           'RPN_NEGATIVE_OVERLAP': 0.3,\n",
      "           'RPN_NMS_THRESH': 0.7,\n",
      "           'RPN_POSITIVE_OVERLAP': 0.7,\n",
      "           'RPN_POSITIVE_WEIGHT': -1.0,\n",
      "           'RPN_POST_NMS_TOP_N': 2000,\n",
      "           'RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SCALES': [600],\n",
      "           'SNAPSHOT_ITERS': 5000,\n",
      "           'SNAPSHOT_KEPT': 3,\n",
      "           'SNAPSHOT_PREFIX': 'res101_mask_rcnn',\n",
      "           'STEPSIZE': [30000],\n",
      "           'SUMMARY_INTERVAL': 180,\n",
      "           'TRUNCATED': False,\n",
      "           'USE_ALL_GT': True,\n",
      "           'USE_FLIPPED': True,\n",
      "           'USE_GT': False,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'USE_GPU_NMS': True}\n",
      "pretrained-model loaded from [/datasets/Kranthi/Maitreya/Manish/ARN/tools/../lib/mrcn/../../pyutils/mask-faster-rcnn/output/res101/coco_2014_train_minus_refer_valtest+coco_2014_valminusminival/notime/res101_mask_rcnn_iter_1250000.pth].\n",
      "FeatLoader loading [ann] from ../cache/feats/refcoco_unc/mrcn/res101_coco_minus_refer_notime_ann_feats.h5 [feat_dim 2048]\n"
     ]
    }
   ],
   "source": [
    "feats_dir = '%s_%s_%s' % (args.net_name, args.imdb_name, args.tag)\n",
    "head_feats_dir = osp.join('../cache/feats/', opt['dataset_splitBy'], 'mrcn', feats_dir)\n",
    "\n",
    "loader.prepare_mrcn(head_feats_dir, args)\n",
    "\n",
    "ann_feats = osp.join('../cache/feats', opt['dataset_splitBy'], 'mrcn',\n",
    "                     '%s_%s_%s_ann_feats.h5' % (opt['net_name'], opt['imdb_name'], opt['tag']))\n",
    "loader.loadFeats({'ann': ann_feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py:3289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py:3226: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "data = loader.getBatch('train', opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'enc_labels', 'dec_labels', 'ref_ids', 'sent_ids', 'gd_ixs', 'gd_boxes', 'cxt_ann_ids', 'Feats', 'att_labels', 'select_ixs', 'bounds'])\n"
     ]
    }
   ],
   "source": [
    "print((data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45477, 45478]\n"
     ]
    }
   ],
   "source": [
    "print(data['ref_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fc7', 'pool5', 'lfeats', 'dif_lfeats', 'cxt_fc7', 'cxt_lfeats'])\n"
     ]
    }
   ],
   "source": [
    "print(data['Feats'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(data['Feats']['cxt_fc7'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_feats = osp.join('../cache/feats', opt['dataset_splitBy'], 'mrcn',\n",
    "                         '%s_%s_%s_ann_feats.h5' % (opt['net_name'], opt['imdb_name'], opt['tag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_fts = h5py.File(ann_feats, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196771, 1024)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_fts['pool5'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/modules/rnn.py:47: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "opt['vocab_size'] = loader.vocab_size\n",
    "opt['fc7_dim'] = loader.fc7_dim\n",
    "opt['pool5_dim'] = loader.pool5_dim\n",
    "opt['num_atts'] = loader.num_atts\n",
    "model = AdaptiveReconstruct(opt).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=opt['learning_rate'],\n",
    "                                 betas=(opt['optim_alpha'], opt['optim_beta']),\n",
    "                                 eps=opt['optim_epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['labels']\n",
    "enc_labels = data['enc_labels']\n",
    "dec_labels = data['dec_labels']\n",
    "Feats = data['Feats']\n",
    "att_labels, select_ixs = data['att_labels'], data['select_ixs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-284fc5cbb276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0matt_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m scores, losses,_,_,_,_,_ = model(Feats['pool5'], Feats['fc7'], Feats['lfeats'], Feats['dif_lfeats'],\n\u001b[0m\u001b[1;32m      3\u001b[0m                                          Feats['cxt_fc7'], Feats['cxt_lfeats'], labels, enc_labels, dec_labels, att_labels, select_ixs, att_weights)\n\u001b[1;32m      4\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/Kranthi/Maitreya/Manish/ARN/tools/../lib/layers/match.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pool5, fc7, lfeats, dif_lfeats, cxt_fc7, cxt_lfeats, labels, enc_labels, dec_labels, att_labels, select_ixs, att_weights)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdif_lfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxt_fc7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxt_lfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/Kranthi/Maitreya/Manish/ARN/tools/../lib/layers/lang_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_labels)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (n, seq_len, word_embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (n, seq_len, word_embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (n, seq_len, word_embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "att_weights = loader.get_attribute_weights()\n",
    "scores, losses,_,_,_,_,_ = model(Feats['pool5'], Feats['fc7'], Feats['lfeats'], Feats['dif_lfeats'],\n",
    "                                         Feats['cxt_fc7'], Feats['cxt_lfeats'], labels, enc_labels, dec_labels, att_labels, select_ixs, att_weights)\n",
    "losses['loss'].backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_encoder.embedding.weight\n",
      "rnn_encoder.mlp.0.weight\n",
      "rnn_encoder.mlp.0.bias\n",
      "rnn_encoder.rnn.weight_ih_l0\n",
      "rnn_encoder.rnn.weight_hh_l0\n",
      "rnn_encoder.rnn.bias_ih_l0\n",
      "rnn_encoder.rnn.bias_hh_l0\n",
      "rnn_encoder.rnn.weight_ih_l0_reverse\n",
      "rnn_encoder.rnn.weight_hh_l0_reverse\n",
      "rnn_encoder.rnn.bias_ih_l0_reverse\n",
      "rnn_encoder.rnn.bias_hh_l0_reverse\n",
      "weight_fc.weight\n",
      "weight_fc.bias\n",
      "sub_attn.fc.weight\n",
      "sub_attn.fc.bias\n",
      "loc_attn.fc.weight\n",
      "loc_attn.fc.bias\n",
      "rel_attn.fc.weight\n",
      "rel_attn.fc.bias\n",
      "sub_encoder.pool5_normalizer.weight\n",
      "sub_encoder.fc7_normalizer.weight\n",
      "loc_encoder.lfeats_normalizer.weight\n",
      "loc_encoder.dif_lfeat_normalizer.weight\n",
      "rel_encoder.vis_feat_normalizer.weight\n",
      "rel_encoder.lfeat_normalizer.weight\n",
      "sub_score.feat_fuse.0.weight\n",
      "sub_score.feat_fuse.0.bias\n",
      "sub_score.feat_fuse.2.weight\n",
      "sub_score.feat_fuse.2.bias\n",
      "loc_score.feat_fuse.0.weight\n",
      "loc_score.feat_fuse.0.bias\n",
      "loc_score.feat_fuse.2.weight\n",
      "loc_score.feat_fuse.2.bias\n",
      "rel_score.feat_fuse.0.weight\n",
      "rel_score.feat_fuse.0.bias\n",
      "rel_score.feat_fuse.2.weight\n",
      "rel_score.feat_fuse.2.bias\n",
      "sub_decoder.mlp.0.weight\n",
      "sub_decoder.mlp.0.bias\n",
      "loc_decoder.mlp.0.weight\n",
      "loc_decoder.mlp.0.bias\n",
      "rel_decoder.mlp.0.weight\n",
      "rel_decoder.mlp.0.bias\n",
      "att_res_loss.att_fc.weight\n",
      "att_res_loss.att_fc.bias\n",
      "lang_res_loss.embedding.weight\n",
      "lang_res_loss.mlp.0.weight\n",
      "lang_res_loss.mlp.0.bias\n",
      "lang_res_loss.rnn.weight_ih_l0\n",
      "lang_res_loss.rnn.weight_hh_l0\n",
      "lang_res_loss.rnn.bias_ih_l0\n",
      "lang_res_loss.rnn.bias_hh_l0\n",
      "lang_res_loss.slr_mlp.0.weight\n",
      "lang_res_loss.slr_mlp.0.bias\n",
      "lang_res_loss.fc.weight\n",
      "lang_res_loss.fc.bias\n",
      "rec_loss.embedding.weight\n",
      "rec_loss.mlp.0.weight\n",
      "rec_loss.mlp.0.bias\n",
      "rec_loss.rnn.weight_ih_l0\n",
      "rec_loss.rnn.weight_hh_l0\n",
      "rec_loss.rnn.bias_ih_l0\n",
      "rec_loss.rnn.bias_hh_l0\n",
      "rec_loss.fc.weight\n",
      "rec_loss.fc.bias\n",
      "sub_mlp.0.weight\n",
      "sub_mlp.0.bias\n",
      "loc_mlp.0.weight\n",
      "loc_mlp.0.bias\n",
      "rel_mlp.0.weight\n",
      "rel_mlp.0.bias\n",
      "feat_fuse.0.weight\n",
      "feat_fuse.0.bias\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "#     if(\"decoder\" in param[0]):\n",
    "        print(param[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.resetIterator(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py:3289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py:3226: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "10834\n",
      "0.15599614186154473\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "prob_sum = 0\n",
    "sent_sum = 0\n",
    "ann = numpy.zeros(70)\n",
    "for i in range(1500):\n",
    "    data = loader.getTestBatch(split, opt)\n",
    "    sents = len(data['sent_ids'])\n",
    "    anns = len(data['ann_ids'])\n",
    "    prob_sum += (1.0 * sents) / (1.0*anns)\n",
    "    sent_sum += sents\n",
    "    num += 1\n",
    "    ann[anns] += 1\n",
    "\n",
    "ann = 100.0*ann/(1.0*1500)\n",
    "print(num)\n",
    "print(sent_sum)\n",
    "print(prob_sum/sent_sum)\n",
    "print(max_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8a3f982100>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "55.93333333333334\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(50):\n",
    "    per += ann[i]\n",
    "    if(per >= 50):\n",
    "        print(i)\n",
    "        print(per)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py:3289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/kranthi/.conda/envs/pytorch_1.5_a/lib/python3.8/site-packages/torch/nn/functional.py:3226: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "data = loader.getTestBatch(split, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30384, 30385, 30386, 30387, 30388, 30389]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sent_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3]\n"
     ]
    }
   ],
   "source": [
    "a = [10,20,5,30]\n",
    "b = numpy.argsort(a)[:4]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n",
      "a3 b4\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "b = 4\n",
    "for i in range(10):\n",
    "    print(\"a%s b%s\"%(a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
